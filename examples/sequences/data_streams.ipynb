{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Streams\n",
    "\n",
    "A data stream is a fa√ßade bringing together an input sequence and an output processing\n",
    "pipe which are not directly connected. Instead, you get samples from the input and pass\n",
    "them to the output only when ready. Though unusual, this pattern becomes useful, eg,\n",
    "when the user has to interact asyncronously with the dataset.\n",
    "\n",
    "First, we need a toy dataset to play with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelime.sequences import SamplesSequence\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"toy_dataset\", ignore_errors=True)\n",
    "for _ in SamplesSequence.toy_dataset(10).to_underfolder(\"toy_dataset\"):  # type: ignore\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a DataStream object and get the first sample (NB: **cache is disabled** on\n",
    "these items, so they are always up-to-date):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelime.sequences import SamplesSequence, DataStream\n",
    "from pipelime.items import JsonMetadataItem\n",
    "\n",
    "# getting data\n",
    "# NB: cache is disabled on these items\n",
    "data_stream = DataStream.read_write_underfolder(\"toy_dataset\")\n",
    "s0 = data_stream[0]  # or data_stream.get_input(0)\n",
    "print(\"original label:\", s0[\"label\"]())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change a value on the sample, this will not be automatically propagated to the\n",
    "original dataset (of course!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "new_s0 = s0.set_value(\"label\", s0[\"label\"]() + np.random.normal(0, 0.1))  # type: ignore\n",
    "print(\"noisy label:\", new_s0[\"label\"]())\n",
    "print(\"original label:\", s0[\"label\"]())\n",
    "print(\n",
    "    'new_s0[\"label\"]() != s0[\"label\"]():',\n",
    "    not np.array_equal(new_s0[\"label\"](), s0[\"label\"]())  # type: ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add a new item to the sample and, eventually, write back the changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_s0 = new_s0.set_item(\"new_meta\", JsonMetadataItem([np.random.randint(100, 110)]))\n",
    "print(\"new metadata:\", new_s0[\"new_meta\"]())\n",
    "\n",
    "print(\"now saving...\")\n",
    "data_stream.set_output(0, new_s0, [\"label\", \"new_meta\"])  # just saving changed keys\n",
    "print(\"now look at ./toy_dataset/data/0_new_meta.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the original sample `s0` will be updated as well, except for the new item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"original sample label:\", s0[\"label\"]())\n",
    "print(\n",
    "    'new_s0[\"label\"]() == s0[\"label\"]():',\n",
    "    np.array_equal(new_s0[\"label\"](), s0[\"label\"]())  # type: ignore\n",
    ")\n",
    "print('\"new_meta\" not in s0:', \"new_meta\" not in s0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the new item, just get again the sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"now getting the sample again...\")\n",
    "s0 = data_stream.get_input(0)\n",
    "print('\"new_meta\" in s0:', \"new_meta\" in s0)\n",
    "print(\n",
    "    'new_s0[\"new_meta\"]() == s0[\"new_meta\"]():', new_s0[\"new_meta\"]() == s0[\"new_meta\"]()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same applies if we add a new sample at the end of the dataset (NB: the zfilling is\n",
    "fixed, so that old samples can still be read and written):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelime.items import NumpyItem\n",
    "\n",
    "print(\"adding new_s0 at the end...\")\n",
    "data_stream.set_output(10, new_s0)\n",
    "last_s0 = data_stream.get_input(10)\n",
    "print(\"new_s0 keys:\", list(last_s0.keys()))\n",
    "print(\"last_s0 keys:\", list(last_s0.keys()))\n",
    "print(\n",
    "    \"list(last_s0.keys()) == list(new_s0.keys()):\",\n",
    "    list(last_s0.keys()) == list(new_s0.keys()),\n",
    ")\n",
    "print(\n",
    "    \"all items equal: \",\n",
    "    all(\n",
    "        np.array_equal(i0(), i1(), equal_nan=True)  # type: ignore\n",
    "        if isinstance(i0, NumpyItem)\n",
    "        else i0() == i1()\n",
    "        for i0, i1 in zip(last_s0.values(), new_s0.values())\n",
    "    )\n",
    ")\n",
    "print(\"now look at ./toy_dataset/data/10*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can always go through all the items as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in enumerate(data_stream):\n",
    "    print(f\"#{i}:\", list(s.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ngp_pl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e2e4dbe5f5bcc7c074081b1f71ddc6c3aca84eb867ecd20f45a2031b7b3b5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
